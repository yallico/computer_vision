
@online{bargoti_deep_2016,
	title = {Deep Fruit Detection in Orchards},
	url = {https://arxiv.org/abs/1610.03677v2},
	abstract = {An accurate and reliable image based fruit detection system is critical for supporting higher level agriculture tasks such as yield mapping and robotic harvesting. This paper presents the use of a state-of-the-art object detection framework, Faster R-{CNN}, in the context of fruit detection in orchards, including mangoes, almonds and apples. Ablation studies are presented to better understand the practical deployment of the detection network, including how much training data is required to capture variability in the dataset. Data augmentation techniques are shown to yield significant performance gains, resulting in a greater than two-fold reduction in the number of training images required. In contrast, transferring knowledge between orchards contributed to negligible performance gain over initialising the Deep Convolutional Neural Network directly from {ImageNet} features. Finally, to operate over orchard data containing between 100-1000 fruit per image, a tiling approach is introduced for the Faster R-{CNN} framework. The study has resulted in the best yet detection performance for these orchards relative to previous works, with an F1-score of {\textgreater}0.9 achieved for apples and mangoes.},
	titleaddon = {{arXiv}.org},
	author = {Bargoti, Suchet and Underwood, James},
	urldate = {2024-10-04},
	date = {2016-10-12},
	langid = {english},
	file = {Full Text PDF:/home/yallicol/Zotero/storage/NYYJ9JL3/Bargoti and Underwood - 2016 - Deep Fruit Detection in Orchards.pdf:application/pdf},
}

@article{linker_determination_2012,
	title = {Determination of the number of green apples in {RGB} images recorded in orchards},
	volume = {81},
	issn = {0168-1699},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169911002638},
	doi = {10.1016/j.compag.2011.11.007},
	abstract = {This work details the development and validation of an algorithm for estimating the number of apples in color images acquired in orchards under natural illumination. Ultimately, this algorithm is intended to enable estimation of the orchard yield and be part of a management decision support system. The algorithm includes four main steps: detection of pixels that have a high probability of belonging to apples, using color and smoothness; formation and extension of “seed areas”, which are connected sets of pixels that have a high probability of belonging to apples; segmentation of the contours of these seed areas into arcs and amorphous segments; and combination of these arcs and comparison of the resulting circle with a simple model of an apple. The performance of the algorithm is investigated using two datasets. The first dataset consists of images recorded in full automatic mode of the camera and under various lighting conditions. Although the algorithm detects correctly more than 85\% of the apples visible in the images, direct illumination and color saturation cause a large number of false positive detections. The second dataset consists of images that were manually underexposed and recorded under mostly diffusive light (close to sunset). For such images the correct detection rate is close to 95\% while the false positive detection rate is less than 5\%.},
	pages = {45--57},
	journaltitle = {Computers and Electronics in Agriculture},
	shortjournal = {Computers and Electronics in Agriculture},
	author = {Linker, Raphael and Cohen, Oded and Naor, Amos},
	urldate = {2024-10-04},
	date = {2012-02-01},
	keywords = {Computer vision, Fruit recognition, Image processing},
	file = {PDF:/home/yallicol/Zotero/storage/EKX3PBH2/Linker et al. - 2012 - Determination of the number of green apples in RGB images recorded in orchards.pdf:application/pdf},
}

@online{noauthor_apples_nodate,
	title = {Apples \& Pears - United Kingdom {\textbar} Statista Market Forecast},
	url = {https://www.statista.com/outlook/cmo/food/fruits-nuts/fresh-fruits/apples-pears/united-kingdom},
	abstract = {The Apples \& Pears market in the United Kingdom is projected to grow by 3.63\% (2024-2029) resulting in a market volume of {US}\$2.94bn in 2029.},
	titleaddon = {Statista},
	urldate = {2024-10-19},
	langid = {english},
	file = {Snapshot:/home/yallicol/Zotero/storage/JTLQTXIW/united-kingdom.html:text/html},
}

@article{gene-mola_kfuji_2019,
	title = {{KFuji} {RGB}-{DS} database: Fuji apple multi-modal images for fruit detection with color, depth and range-corrected {IR} data},
	volume = {25},
	issn = {2352-3409},
	url = {https://www.sciencedirect.com/science/article/pii/S2352340919306432},
	doi = {10.1016/j.dib.2019.104289},
	shorttitle = {{KFuji} {RGB}-{DS} database},
	abstract = {This article contains data related to the research article entitle “Multi-modal Deep Learning for Fruit Detection Using {RGB}-D Cameras and their Radiometric Capabilities” [1]. The development of reliable fruit detection and localization systems is essential for future sustainable agronomic management of high-value crops. {RGB}-D sensors have shown potential for fruit detection and localization since they provide 3D information with color data. However, the lack of substantial datasets is a barrier for exploiting the use of these sensors. This article presents the {KFuji} {RGB}-{DS} database which is composed by 967 multi-modal images of Fuji apples on trees captured using Microsoft Kinect v2 (Microsoft, Redmond, {WA}, {USA}). Each image contains information from 3 different modalities: color ({RGB}), depth (D) and range corrected {IR} intensity (S). Ground truth fruit locations were manually annotated, labeling a total of 12,839 apples in all the dataset. The current dataset is publicly available at http://www.grap.udl.cat/publicacions/datasets.html.},
	pages = {104289},
	journaltitle = {Data in Brief},
	shortjournal = {Data in Brief},
	author = {Gené-Mola, Jordi and Vilaplana, Verónica and Rosell-Polo, Joan R. and Morros, Josep-Ramon and Ruiz-Hidalgo, Javier and Gregorio, Eduard},
	urldate = {2024-11-01},
	date = {2019-08-01},
	keywords = {Depth cameras, Fruit detection, Fruit reflectance, Fuji apple, Multi-modal dataset, {RGB}-D},
	file = {Full Text:/home/yallicol/Zotero/storage/7NHE4PSG/Gené-Mola et al. - 2019 - KFuji RGB-DS database Fuji apple multi-modal images for fruit detection with color, depth and range.pdf:application/pdf;ScienceDirect Snapshot:/home/yallicol/Zotero/storage/TJVD5HV7/S2352340919306432.html:text/html},
}

@article{murillo-bracamontes_implementation_2012,
	title = {Implementation of Hough transform for fruit image segmentation},
	volume = {35},
	issn = {1877-7058},
	url = {https://www.sciencedirect.com/science/article/pii/S1877705812018206},
	doi = {10.1016/j.proeng.2012.04.185},
	series = {International Meeting of Electrical Engineering Research 2012.},
	abstract = {A computer vision system tries to mimic our primary sense (sight) in order to gather information without the need for physical interaction, in fact such systems are able to grade automatically, and extract useful information with a degree of sensitivity closer to that of a human, reducing considerably the margin of error. By performing digital image processing, defined as the acquisition and processing of visual information by computer, computer vision systems allow analyzing image data for specific applications in order to determine how images can be used to extract the required information. Among the most important features for accurate classification and sorting of products it can be mentioned the shape. The shape of objects or regions of interest are important features used for content representation, and require good segmentation to detect objects or regions. Basically, shape characterization is of two types: boundary-based and regionbased. Boundary-based shape features include rectilinear shapes, polygonal approximation, finite element models, and Fourier-based shape descriptors. Region-based features include statistical moments and grid-based approaches. Object shape detection using a technique based on Hough Transform for further segmentation is presented on this paper.},
	pages = {230--239},
	journaltitle = {Procedia Engineering},
	shortjournal = {Procedia Engineering},
	author = {Murillo-Bracamontes, Eduardo A. and Martinez-Rosas, Miguel E. and Miranda-Velasco, Manuel M. and Martinez-Reyes, Horacio L. and Martinez-Sandoval, Jesus R. and Cervantes-de-Avila, Humberto},
	urldate = {2024-11-27},
	date = {2012-01-01},
	keywords = {Image processing, {CIELAB}, {CLAHE}, Hough transform, vision system},
	file = {PDF:/home/yallicol/Zotero/storage/UJ6VMI7A/Murillo-Bracamontes et al. - 2012 - Implementation of Hough transform for fruit image segmentation.pdf:application/pdf},
}
