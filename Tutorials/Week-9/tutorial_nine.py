# -*- coding: utf-8 -*-
"""Tutorial_nine(1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12C3cDuD32CrI6DMNXyyaQqOo4rO4TXkx

### A vanilla CNN for object detection (binary classification + localisation)
The output values are (objectness & 4 bounding box values)
"""

import keras
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import datasets

import numpy as np

# use 20 images to train the model
no_of_images = 20

# make some fake label values as an example, assuming we have 1 class only
# 0 representing background and 1 representing the object
train_class = np.random.randint(0, 2, no_of_images)

# load the cifar10 dataset
(train_images, _), (_, _) = datasets.cifar10.load_data()
# use only the first 20 images
train_images = train_images[0:no_of_images, :, :, :]

# make some fake bounding box data (number_of_images, x, y, width, height)
train_loc = tf.random.uniform([tf.shape(train_images)[0], 4])
# combine the class labels and the bounding box labels as training labels
train_labels = (train_class, train_loc)

# pretend that we have some test images, but I really only made a copy of the 
# training images and labels
test_images = train_images.copy()  
test_labels = train_labels

print(train_labels) # see below what these labels look like
# you can see that these bounding box values are scaled to between 0 and 1.
# as a percentage relative to the height and width of images

opt = tf.keras.optimizers.Adam(learning_rate=0.0001) # choose an optimizer - no need to understand

# Adam
# use some existing CNN architecture - VGG used here, with pre-trained weights
# remove the dense layers by "include_top" = False. We will add some dense layers
# ourselves later
base_model = tf.keras.applications.VGG16(weights="imagenet", include_top=False)

# add a global average pooling layer to the convolutional based
avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)

# add 1 neuron for the class label to the output layer.
# use sigmoid activation function to make this output a float value between 0 and 1
class_output = tf.keras.layers.Dense(1, activation="sigmoid")(avg)

# add 4 additional neurons to the output layer, as x, y, width and height
# for the bounding box position
loc_output = tf.keras.layers.Dense(4)(avg)

# combine the 5 neurons to make the output layer
model = tf.keras.Model(inputs=base_model.input, outputs=[class_output, loc_output])

# use binary cross entropy loss for class prediction and mse loss for bounding box
# regression
model.compile(loss=["binary_crossentropy", "mse"], loss_weights=[0.8, 0.2], optimizer=opt, metrics=["accuracy"])

model.summary()

history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))

# You can see the predicted "objectness" score below (first 20 elements)
# and then the bounding box results
result = model.predict(test_images)
print(result)